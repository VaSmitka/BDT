{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful Python functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String length is: 18\n",
      "String contains words: ['to', 'be', 'Or', 'NOT', 'to', 'be']\n",
      "String contains unique words: {'Or', 'be', 'to', 'NOT'}\n",
      "String to lowercase:  to be or not to be\n",
      "Array/list length (number of words) is: 6\n",
      "The first item in array is: to\n",
      "The last item in array is: be\n"
     ]
    }
   ],
   "source": [
    "my_string = \"to be Or NOT to be\"\n",
    "my_list = my_string.split()\n",
    "print 'String length is:', len(my_string)\n",
    "print 'String contains words:', my_string.split()\n",
    "print 'String contains unique words:', set(my_string.split())\n",
    "print 'String to lowercase: ', my_string.lower()\n",
    "print 'Array/list length (number of words) is:', len(my_list)\n",
    "print 'The first item in array is:', my_list[0]\n",
    "print 'The last item in array is:', my_list[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch the interactive shell PySpark\n",
    "\n",
    "`pyspark --master yarn --num-executors 4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string(verse):    \n",
    "    return verse.split(' ')\n",
    "\n",
    "lines = sc.textFile(\"/user/pascepet/data/bible.txt\")\n",
    "words = lines.flatMap(split_string)\n",
    "pairs = words.map(lambda word: (word, 1))\n",
    "counts = pairs.reduceByKey(lambda a, b: a + b)\n",
    "counts.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust the above example \"word count\" (in any order):\n",
    "\n",
    "1. Choose RDD which is useful to be cached and cache it.\n",
    "1. Sort the results by frequency in descending order (Hint: sortBy nebo sortByKey).\n",
    "1. Count the word no matter of upper- or lowercase (god, God and GOD should be same word).\n",
    "1. Omit the identifying part of each line (Bible book and chapter:verse -- divided by tab \\t).\n",
    "1. Get rid of non-alphanumeric characters from the text ('.', ':', '-' etc. -- or at least some of them).\n",
    "1. Do not take into account \"stop-words\". \n",
    "\n",
    "### Data\n",
    "\n",
    "`/user/pascepet/data/bible.txt` at HDFS\n",
    "`/user/pascepet/data/stopwords.txt` at HDFS\n",
    "\n",
    "### Hint\n",
    "\n",
    "`# stop-words reading into Python set`    \n",
    "`sw = set(sc.textFile('/user/pascepet/data/stopwords.txt').collect())`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Count words in each verse (1 verse = 1 line) and find the verses with the highest and lowest number of words.  \n",
    "b) Do the same calculation as in a) but count only unique words in each verse.\n",
    "\n",
    "### Data\n",
    "\n",
    "`/user/pascepet/bible.txt` na HDFS\n",
    "\n",
    "### Expected result\n",
    "\n",
    "| verse_id | word_count |  \n",
    "| -------- | ----------:|  \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Get the state with the highest average temperature over months 6--8. Write the results in Celsius degrees.  \n",
    "b) For each month get the state with the highest average temperature in that months.\n",
    "\n",
    "### Data\n",
    "\n",
    "1. Find the file `/home/pascepet/fel_bigdata/data/teplota-usa.zip` on the local filesystem (not at HDFS).\n",
    "1. Copy this file to your working directory on the local filesystem.\n",
    "1. Unzip the file. You will get two files CSV. Join them into one file `teplota.csv`.\n",
    "1. The file `teplota.csv` copy to HDFS to your user directory.\n",
    "\n",
    "### Data description\n",
    "\n",
    "CSV file is delimited by ','. It has headers with column names which we need to filter out.        \n",
    "The temperature is in 10 * Fahrenheit degrees.     \n",
    "Some row have no temperature measured (empty string).\n",
    "\n",
    "**Columns:** id_station, month, day, hour, temperature, flag, latitude, longitude, hight, state, name\n",
    "\n",
    "\n",
    "### Expected result\n",
    "\n",
    "In a) section\n",
    "\n",
    "| stat | avg_temperature |  \n",
    "| ---- | ---------------:|  \n",
    "\n",
    "In b) section\n",
    "\n",
    "| month | state | avg_temperature |  \n",
    "| ----- | ----- | ---------------:|  \n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
